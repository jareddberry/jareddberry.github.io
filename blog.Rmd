---
title: "Blog"
output:
  html_document:
    theme: sandstone
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

### A Capstone By Another Name (Goodbye EViews)

[End-to-end Exchange Rate Forecasting Capstone Pipeline](files/case-study.R)

In the "Research" tab above, I've posted my capstone (examining the role of “fundamentals” (or theory) in long-term exchange rate forecasting) from my master's program. As a part of the MIEF Winter Intercession this year, I led an "R for Capstone: Case-Study," as the latest chapter in my efforts to normalize R as a better alternative to the proprietary languages that typically dominate econometrics coursework. The R script above establishes an end-to-end analytics pipeline from data ingestion to reporting that constitutes a majority of the analysis featured in this research. In particular, I leverage `quantmod`, which is a phenomenal package for rapidly ingesting financial and macroeconomic time-series data from [FRED](https://fred.stlouisfed.org/) and Yahoo! Finance, without the trouble of using something like `httr` to pull data from an API. With this lightweight ingestion set up, one *should* be able to pull this R script off the shelf, install all the requisite packages, and run all the same analysis (with visualizations and regression tables vis-a-vis `stargazer`!).

### Edit Distance and Approximate String Matching
[Edit Distance](files/edit_distance.html)  
[Download RMarkdown](files/edit_distance.Rmd)

Distance metrics are excellent for implementing approximate string matching, whether as an initial step in entity resolution or building out programs to execute algorithms similar to those one would see in predictive text and spell check. This post delves into a dynamic programming implementation of edit distance to understand how things work "under-the-hood", and then provides examples of using the built in `adist` and `agrep` functions readily available in R.

### Scraping PDFs in R with `pdftools` and `stringr`

[PDF scraping in R](files/scraping_pdfs_in_r.html)  
[Download RMarkdown](files/scraping_pdfs_in_r.Rmd)

With the sheer volume at our disposal in today's world, it's no surprise that much of it is not neatly-packaged for use "out-of-the-box." This brief tutorial demonstrates the uses of `pdftools` and `stringr` to automate the processing of tables that come in PDF files (e.g. tables available in newsletters, statistical releases, earnings reports, etc.). With a bit of regular expression know-how, and these packages, one can scrape tables off PDFs into tidy, tabular formats for further use in analytics pipelines.

### Building heatmaps in R with `dplyr` and `ggplot2`

[Heatmaps in R](files/heatmaps_in_r.html)  
[Download RMarkdown](files/heatmaps_in_r.Rmd)

For my inaugural post in this blog I'm revisiting one of the first challenges I came up against in my time as an analyst at the Board. I didn't fully appreciate the power of R prior to working through this exercise, and was blown away by how simple it can be to build incredible visualizations in R. This is a brief tutorial using the `dplyr` and `ggplot2` libraries to work through the process of cleaning a poorly-formatted dataset and harness the power of the `ggplot2` library to turn that data into a geographical heatmap of the United States, at the *county* level.

***
