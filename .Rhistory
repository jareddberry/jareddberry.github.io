knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Jared/Documents/datasci/projects/pdf_scrape")
library(pdftools)
library(stringr)
library(purrr)
# Set path to the newsletter we want to scrape
pdf_name <- "g20.pdf"
# Read in newsletter text using the pdftools module
afs_text <- pdf_text(pdf_name)
g20_text <- pdf_text(pdf_name)
g20_text
str(g20_text)
substr(g20_text[1],1,1000)
# Separate out the page which contains the table of interest
last_page <- g20_text[[2]]
# Inspect
substr(last_page,1,1000)
g20_table_raw <- str_split(last_page, "\r\n", simplify=TRUE)
str(g20_table_raw)
g20_table_raw
row_expr <- paste(c("Owned", "Footnotes", "Billions", "adjusted"), collapse = "|")
row_expr
g20_table_raw[-str_detect(afs_table_raw, row_expr)]
str_detect(g20_table_raw, row_expr)
g20_table <- g20_table_raw[which(!str_detect(g20_table_raw, row_expr))]
g20_table
elements <- map(g20_table, function(x) str_split(x, "\\s+", simplify = TRUE))
elements[[1]]
elements[[4]]
elements
# Separate out the page which contains the table of interest
last_page <- g20_text[[length(g20_text)]]
g20_table_raw <- str_split(last_page, "\r\n", simplify=TRUE)
str(g20_table_raw)
print(g20_table_raw)
# Separate out the page which contains the table of interest
last_page <- g20_text[[2]]
# Separate out the page which contains the table of interest
table_page <- g20_text[[2]]
# Split full table into individual lines of text based on '\n' line break character
g20_table_raw <- str_split(table_page, "\r\n", simplify=TRUE)
# Assemble a regular expression to identify table entries of interest
row_expr <- paste(c("Owned", "Footnotes", "Billions", "adjusted"), collapse = "|")
row_expr
# Remove rows which do not contain values for input based on names from PDF
g20_table <- g20_table_raw[which(!str_detect(g20_table_raw, row_expr))]
elements[[4]]
row_expr <- paste(c("Owned", "Footnotes", "Billions", "adjusted"), collapse = "|")
row_expr
# Remove rows which do not contain values for input based on names from PDF
g20_table <- g20_table_raw[which(!str_detect(g20_table_raw, row_expr))]
g20_table
sapply(g20_table, str_replace, ",", "")
g20_table
str(g20_table)
map_chr(g20_table, str_replace, pattern=",", replacement="")
map_chr(g20_table, str_replace_all, pattern=",", replacement="")
# Assemble a regular expression to identify table entries of interest
row_expr <- paste(c("Owned", "Footnotes", "Billions", "adjusted"), collapse = "|")
row_expr
# Remove rows which do not contain values for input based on names from PDF
g20_table <- g20_table_raw[which(!str_detect(g20_table_raw, row_expr))]
# Remove commmas
g20_table <- map_chr(g20_table, str_replace_all, pattern=",", replacement="")
# Split at any number of spaces
elements <- map(g20_table, function(x) str_split(x, "\\s+", simplify = TRUE))
elements[[4]]
entry_expr <- "[0-9]*\\.[0-9]*"
num_values <- map(elements, function(x) as.numeric(x[str_detect(x, entry_expr)]))
g20_values <- do.call("rbind", num_values)
g20_values
elemetns
elements
str_values <- map(elements, function(x) as.numeric(x[str_detect(x, "[A-z]")]))
str_values
# Remove unnecessary text to convert table values from text to numeric
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
str_values
elements
# Remove unnecessary text to convert table values from text to numeric
str_values <- map(elements, function(x) paste(x[str_detect(x, "[A-z]")]))
str_values
str_values <- map(str_values, paste)
str_values
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
map(str_values, str_c, sep=" ")
str_values <- map(str_values, function(x) str_c(x[[1]] sep=" "))
str_values <- map(str_values, function(x) str_c(x[[1]], sep=" "))
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
str_values[[1]]
str_values[[2]]
str_c(str_values[[2]])
str_c(str_values[[2]], collapse=T
)
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
str_values <- map(str_values, str_c, collapse=" ")
str_values
# Drop footnotes
row_names <- flatten_chr(str_values)
row_names
row_names <- str_replace(row_names, "[0-9]", "")
row_names
# Drop header info
row_names <- row_names(which(str_detect(row_names, "^[A-Z][a-z]")))
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
str_values <- map(str_values, str_c, collapse=" ")
# Drop footnotes
row_names <- flatten_chr(str_values)
row_names <- str_replace(row_names, "[0-9]", "")
# Drop header info
row_names <- row_names[(which(str_detect(row_names, "^[A-Z][a-z]")))]
row_names
# Recreate row names
str_values <- map(elements, function(x) x[str_detect(x, "[A-z]")])
str_values <- map(str_values, str_c, collapse=" ")
# Drop footnotes
row_names <- flatten_chr(str_values)
row_names <- str_replace(row_names, "[0-9]", "")
# Drop header info
row_names <- row_names[(which(str_detect(row_names, "^[A-Z][a-z]")))]
row.names(g20_values) <- row_names
g20_values
elements
str_values
map(elements, function(x) x[str_detect(x, "Q[1-4]")])
map(elements, str_c, collapse=" ")
header_values <- map(elements, str_c, collapse=" ")
header_values[str_detect(header_values, "Q[1-4]")]
# Recreate headers - identify quarter structure and pull
header_values <- map(elements, str_c, collapse=" ")
header_values <- flatten_chr(header_values[str_detect(header_values, "Q[1-4]")])
# Remove leading space
header_values <- str_trim(header_values, "both")
header_values
# Split to create a vector of headers
header_names <- str_split(header_values, pattern = " ", simplify = T)
header_names
# Recreate headers - identify quarter structure and pull
header_values <- map(elements, str_c, collapse=" ")
header_values <- flatten_chr(header_values[str_detect(header_values, "Q[1-4]")])
# Remove leading space
header_values <- str_trim(header_values, "both")
# Split to create a vector of headers
header_names <- str_split(header_values, pattern = " ", simplify = T)
header_names <- flatten_chr(str_values)
colnames(g20_values) <- header_names
g20_values
header_names
# Recreate headers - identify quarter structure and pull
header_values <- map(elements, str_c, collapse=" ")
header_values <- flatten_chr(header_values[str_detect(header_values, "Q[1-4]")])
# Remove leading space
header_values <- str_trim(header_values, "both")
# Split to create a vector of headers
header_names <- str_split(header_values, pattern = " ", simplify = T)
header_names <- flatten_chr(header_names)
# Recreate headers - identify quarter structure and pull
header_values <- map(elements, str_c, collapse=" ")
header_values <- flatten_chr(header_values[str_detect(header_values, "Q[1-4]")])
# Remove leading space
header_values <- str_trim(header_values, "both")
# Split to create a vector of headers
header_names <- str_split(header_values, pattern = " ", simplify = T)
##header_names <- flatten_chr(header_names)
colnames(g20_values) <- header_names
print(g20_values)
g20_table_raw
g20_table_raw[which(str_detect(g20_table_raw, "[1-2][0-9]{3}"))]
ls()
g20_text[[1]]
months_expr <- "(January|February|March|April|May|June|July|August|September|October|November|December)"
str_extract(g20_text[[1]], paste(months_expr, "[1-2][0-9]{3}"))
release_no <- str_extract_all(g20_text[[1]], paste(months_expr, "[1-2][0-9]{3}"))
release_no
release_no <- flatten_chr(release_no)
release_no
release_no <- str_extract(g20_text[[1]], paste(months_expr, "[1-2][0-9]{3}"))
release_no
if(grepl("October", release_no)) {
year_vec <- c("", "", "", "", "", "2017", "2017", "2018", "2018", "2018", "2018", "2018", "2018")
}
year_vec
if(grepl("October", release_no)) {
year_vec <- c("", "", "", "", "", "_2017", "_2017", "_2018", "_2018", "_2018", "_2018", "_2018", "_2018")
}
paste0(year_vec, colnames(g20_values))
# Pull Month - Year portions of the release - the first will correspond to the month of the underlying data
months_expr <- "(January|February|March|April|May|June|July|August|September|October|November|December)"
release_no <- str_extract(g20_text[[1]], paste(months_expr, "[1-2][0-9]{3}"))
# Skeleton of control flow structure necessary to process releases - built out for October only
if(grepl("October", release_no)) {
year_vec <- c("", "", "", "", "", "_2017", "_2017", "_2018", "_2018", "_2018", "_2018", "_2018", "_2018")
}
colnames(g20_values) <- paste0(colnames(g20_values), year_vec)
print(g20_values)
