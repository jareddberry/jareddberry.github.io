rm(list=ls())

# INSTALL AND/OR ATTACH THESE LIBRARIES
library(dplyr)
library(haven)

# WARM-UP -------------------------------------------------------------

# Read the 'state_unemp_clean.csv' data into memory and assign it to a variable of your choosing
# Convert the 'date' column to the date type (Hint: Use 'as.Date' and reassign it to the 'date' variable)
# What is the highest unemployment rate in the sample?
# Which state has the highest unemployment rate in the sample? In what year was that rate reached?
# What is the average household income across all the states in the sample?
# What is Ohio's average unemployment rate in this time horizon?
# Create a time-series plot of the unemployment rate in the state with the lowest unemployment rate in 2016
# Change the x- and y-labels and plot title to descriptive names
# Using '?plot' for help, change the type of the plot to a line graph

# ---------------------------------------------------------------------

state_unemp <- read.csv("state_unemp_clean.csv", stringsAsFactors=FALSE)


state_unemp$date <- as.Date(state_unemp$date)


max(state_unemp$Unemployment_rate)


state_unemp$State[state_unemp$Unemployment_rate == max(state_unemp$Unemployment_rate)]


state_unemp$date[state_unemp$Unemployment_rate == max(state_unemp$Unemployment_rate)]


mean(state_unemp$Median_Household_Income_2015)


mean(state_unemp$Unemployment_rate[state_unemp$State == "OH"])


unemp_2016 <- state_unemp[state_unemp$date == "2016-01-01",]
unemp_2016$State[unemp_2016$Unemployment_rate == min(unemp_2016$Unemployment_rate) & 
                unemp_2016$date == "2016-01-01"]


plot(state_unemp$date[state_unemp$State == "NH"], state_unemp$Unemployment_rate[state_unemp$State == "NH"])


plot(state_unemp$date[state_unemp$State == "NH"], 
     state_unemp$Unemployment_rate[state_unemp$State == "NH"],
     xlab = "Year", ylab = "Unemployment rate", main = "New Hampshire Unemployment Rate",
     type = "l")


# ---------------------------------------------------------------------

# Load in data
wage_data <- data.frame(read_dta("MROZ.dta"))
salaries_data <- read.csv("Salaries.csv", stringsAsFactors=FALSE)
county_unemp <- read.csv("county_unemp_clean.csv", stringsAsFactors=FALSE)

# PROGRAMMING IN R ----------------------------------------------------

a <- 7

if (a %% 2 == 0) {
  print("even")
} else {
  print("odd")
}

# Control flow
a <- 7

if(a%%2 == 0) {
  print("even")
} else {
  print("odd")
}

ifelse(a%%2 == 0, "even", "odd")

# Functions
square <- function(x) {
 return(x**2)
} 

square(3)
square(x)

# Loops - extending our mix of control flow and conditionals above
a_vector <- c(1,6,7,8,8293,21,888,3,-2)

for(i in 1:length(a_vector)){
  if(a_vector[i]%%2 == 0) {
    print("even")
  } else {
    print("odd")
  }
}

# Specify a random vector using the following syntax
rand_vect <- round(100*runif(100),0)

# PROGRAMMING IN R - PRACTICE -----------------------------------------

# Write a function `cube`, which takes a value and returns that value cubed; write a loop to apply this function to all the elements of the vector; print the cubed values
# Using a loop and control flow, check if each element of the vector is a perfect square, if it is return the index, i, and print "Perfect square!"
# Hint: Use x%%1 to check if your number is a whole number

# Load the 'salaries_list.Rds' object into memory (`readRDS()`)
# Inspect the list; what does each element contain? What is distinct about them?
# Loop through the list, and return the average of the `yrs.since.phd` variable for each element

cube <- function(x) {
  return(x**3)
}

for(i in 1:length(rand_vect)) {
  print(cube(rand_vect[i]))
}

for(i in rand_vect) {
  print(cube(i))
}

for(i in 1:length(rand_vect)) {
  if(sqrt(rand_vect[i])%%1 == 0) {
    print(i)
    print("Perfect square!")
  }
}
    
# DATA ANALYSIS -------------------------------------------------------
  
# Dealing with missing values
a_dataframe <- data.frame(x = c("x", "y", "z"), 
                          y2015 = c(1,2,3), 
                          y2016 = c(9,10,3), 
                          y2017=c(10,NA,3), 
                          stringsAsFactors = FALSE)

summary(a_dataframe)
sum(is.na(a_dataframe))
a_dataframe[complete.cases(a_dataframe),]

library(readxl)
hpi <- data.frame(read_excel("HPI_AT_BDL_county.xlsx", na=c("", "."), skip=6))

colnames(hpi) <- c("state", "county", "FIPStxt", "year", "annual_change", "hpi", "hpi_1990", "hpi_2000")
hpi[,c(5:8)] <- (sapply(hpi[c(5:8)], as.numeric))

summary(hpi)
sum(is.na(hpi))
hpi[complete.cases(hpi),]

# dplyr ---------------------------------------------------------------

# dplyr basics
head(salaries_data)
summary(salaries_data)

select(salaries_data, rank, discipline, yrs.since.phd, yrs.service, sex, salary)
select(salaries_data, c(1,2))
select(salaries_data, starts_with("yrs"))

salaries_data2 <- select(salaries_data, -X)

filter(salaries_data2, rank=="Prof")
filter(salaries_data2, salary>=100000)
filter(salaries_data2, salary>=100000 & sex=="Female")
filter(hpi, !is.na(hpi))

arrange(salaries_data2, salary)
arrange(salaries_data2, desc(salary))
arrange(salaries_data2, sex, rank)

mutate(salaries_data2, bonus="yes")
salaries_data2 <- mutate(salaries_data2, bonus=ifelse(yrs.service>=10, 10000, 2000))

salaries_data2
salaries_data2 <- mutate(salaries_data2, salary=salary + bonus)

salaries_data %>%
  select(-X) %>%
  mutate(bonus=ifelse(yrs.service>=10, 10000, 2000)) %>%
  mutate(salary = salary + bonus) %>%
  select(-bonus) %>%
  arrange(salary) %>%
  filter(sex=="Female")

# dplyr merges---------------------------------------------------------

# Merging, pipes, and group_by
data(state)
str(state.x77)
str(state.region)
str(state.name)

# cbind and rbind - not merges
x <- seq(1:10)
y <- letters[seq(1:10)]
z <- rep(c(TRUE,FALSE), 5)

rbind(x,y,z)
cbind(x,y,z)
data.frame(x,y,z)

cbind(state.name, state.region)
cbind(state.name, as.character(state.region))
cbind(sort(state.name,TRUE), as.character(state.region))

name_region_map <- data.frame(state.name, as.character(state.region))
names(name_region_map) <- c("state", "region")

state.x77
state_info <- cbind(rownames(state.x77), data.frame(state.x77, row.names=NULL))
colnames(state_info)[1] <- "state"

state_info
merge(state_info, name_region_map, by="state")
left_join(state_info, name_region_map, by="state")

left_data <- data.frame(country = c("A", "B", "B", "C", "D", "E", "F"), 
                        left_value = c(1380, 8023, 12301, 682, 542, 1042, 972),
                        stringsAsFactors = FALSE)

right_data <- data.frame(country = c("B", "D", "E", "F", "G", "H", "I"),
                         right_value = c(2.2, 7.8, 12.4, 9.2, 18.3, 1.7, 10.1),
                         stringsAsFactors = FALSE)

#left_join - mutating - match, by key, right-hand data to the left-hand data
left_join(left_data, right_data, by="country")

#right_join - mutating - match, by key, left-hand data to the right-hand data
right_join(left_data, right_data, by="country")
left_join(right_data, left_data, by="country")

#inner_join - mutating - match, by key, and keep only those observations found in both datasets
inner_join(left_data, right_data, by="country")

#full_join - mutating - match, by key, and keep all observations, regardless of which dataset they're found in
full_join(left_data, right_data, by="country")

#semi_join - filtering - match, by key, keeping only the left-hand data, and filter out those which don't have a match in right-hand data
semi_join(left_data, right_data, by="country")

#anti_join - filtering - match, by key, keeping only the left-hand data, and filter out those which do have a match in right-hand data
anti_join(left_data, right_data, by="country")

head(state_unemp)
state_unemp %>%
  select(Area_name, Unemployment_rate) %>%
  group_by(Area_name) %>%
  summarise(Unemployment_rate = mean(Unemployment_rate, na.rm=TRUE))

# DATA ANALYSIS - PRACTICE --------------------------------------------

weo_report <- read.csv("weo_clean.csv", stringsAsFactors = FALSE)
wdi_indicators <- read.csv("wdi_indicators.csv", stringsAsFactors = FALSE)

# Merge in the World Development Indicators indicators data with the WEO data
# Report countries that did not receive valid region or income_group identifers

# Using dplyr and pipes, in one chained command, create a subset of the data that:
# Has only those observations from the "Europe & Central Asia" region from 2016
# Has only the country, gdppc, unemployment_rate, and curr_acc_bal values

# Change the units of unemployment_rate to reflect a percent with a mutate command (divide by 100)
# Find the average unemployment rate for this group
# Create a time-series plot of Danish unemployment over the sample period
# Find the average level of GDP for each income group
# Which region has the largest within-region disparity in GDP per capita, as measured by standard deviation?
# Create histograms of the GDP per capita variable within each region, setting the title of each plot to the name of the region

weo_full <- left_join(weo_report, wdi_indicators, by="country")


unmerged_countries <- filter(weo_full, is.na(region))
unique(unmerged_countries$country)


weo_full <- filter(weo_full, !is.na(region))


eca_weo <-
  weo_full %>%
  filter(region == "Europe & Central Asia" & year == 2016) %>%
  select(country, gdppc, unemployment_rate, curr_acc_bal) %>%
  mutate(unemployment_rate = unemployment_rate/100) %>%
  summarise(mean_unemployment_rate = mean(unemployment_rate, na.rm=TRUE))

eca_weo


dmk_ur <- 
  weo_full  %>%
  filter(country=="Denmark") %>%
  select(country, year, unemployment_rate)

plot(dmk_ur$year, dmk_ur$unemployment_rate, "l")


weo_full %>%
  group_by(income_group) %>%
  summarise(deviation = sd(gdp_cp, na.rm=T)) %>%
  ungroup() %>%
  filter(deviation == max(deviation))

for (region in unique(weo_full$region)) {
  hist(weo_full$gdp_cp[weo_full$region == region], main = region, xlab = "GDP per capita")
}
  
